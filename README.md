# RAG Chatbot Project

A Retrieval-Augmented Generation (RAG) chatbot built with LangChain, ChromaDB, and Streamlit.

## Project Structure

```
rag-chatbot/
â”œâ”€â”€ .venv/                 # Virtual environment
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ .gitignore            # Git ignore file
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ data/                 # Document storage
â”‚   â””â”€â”€ sample_document.txt
â”œâ”€â”€ chroma_db/            # Vector database
â”‚   â””â”€â”€ chroma.sqlite3
â”œâ”€â”€ ingest.py             # Document ingestion script
â”œâ”€â”€ ingest_demo.py        # Demo version (no API calls)
â”œâ”€â”€ query.py              # Query system with LLM
â”œâ”€â”€ query_demo.py         # Demo query system
â”œâ”€â”€ query_test.py         # Test query system
â”œâ”€â”€ hello_streamlit.py    # Test Streamlit app
â””â”€â”€ README.md             # This file
```

## Setup

1. **Environment Setup:**
   ```bash
   python -m venv .venv
   .\.venv\Scripts\Activate.ps1
   pip install -r requirements.txt
   ```

2. **Environment Variables:**
   Update `.env` with your OpenAI API key:
   ```
   OPENAI_API_KEY=your_api_key_here
   # RAG Chatbot (PDF + Streamlit + GPT-3.5)

   > Upload a PDF. Ask it anything. Watch it answer like ChatGPT â€” but trained on your doc.

   Think of this as a tiny local ChatGPT for your PDFs. No cloud secrets (unless you opt in), no magic â€” just you, your docs, and a few open-source building blocks.

   ---

   ## ğŸ§­ TL;DR (Hook)

   Upload a PDF. Ask it anything. Get grounded answers pulled straight from your document(s).

   ---

   ## âš™ï¸ What it does

   - ğŸ“„ Upload PDFs â†’ automatically indexed
   - ğŸ’¬ Chat with your docs using GPT-3.5 (optional)
   - ğŸ” Instant answers grounded in your files (with sources)
   - ğŸ§  Keeps short-term conversation memory for follow-ups
   - ğŸ› ï¸ Runs locally with Streamlit â€” no cloud required

   ---

   ## ğŸ§© How it works (simple breakdown)

   ```
   ğŸ“„ PDF â†’ ğŸ” Text Splitter â†’ ğŸ§  Embeddings â†’ ğŸ’¾ ChromaDB â†’ ğŸ¤– GPT-3.5 â†’ ğŸ’¬ Answer
   ```

   PDF is split into chunks. Each chunk gets an embedding (vector). Vectors are stored in ChromaDB. When you ask a question, the system finds the most relevant chunks and (optionally) asks GPT-3.5 to synthesize a grounded answer using those chunks as context.

   Itâ€™s quick, local, and intentionally minimal â€” perfect for testing ideas or getting instant answers from docs you actually control.

   ---

   ## ğŸš€ Quickstart (for devs)

   Try this â€” should take < 5 minutes if you already have Python and pip:

   ```bash
   git clone https://github.com/SohamDatta-ai/Rag-Chatbot.git
   cd Rag-Chatbot
   pip install -r requirements.txt
   python -m streamlit run app.py
   ```

   ğŸ’¡ Make sure youâ€™ve set your `OPENAI_API_KEY` in a local `.env` if you want GPT-3.5 answers.

   ---

   ## ğŸ§  Stack

   - **LangChain** â†’ orchestration
   - **Chroma** â†’ vector DB
   - **HuggingFace MiniLM-L6-v2** â†’ embeddings
   - **GPT-3.5-Turbo** â†’ answers
   - **Streamlit** â†’ UI

   ---

<<<<<<< HEAD


Beta Realease Coming soon

=======
   ## ğŸŒ Future upgrades (features I want to build)

   - ğŸ”¥ Multi-PDF chat (upload a folder)
   - ğŸ’¾ Cloud vector DB (Pinecone / FAISS / Weaviate)
   - ğŸ§  Personal AI memory (opt-in long-term memory)
   - â˜ï¸ One-click deploy (Heroku / Docker + GH Actions)

   ---

   ## ğŸ’¬ Credits

   Built with â¤ï¸ by [Soham Datta](https://github.com/SohamDatta-ai)

   ---

   ## âœ… Example output (tone preview)

   > **â€œUpload. Ask. Understand.â€**
   >
   > A lightweight RAG chatbot that lets you upload PDFs and chat with them â€” powered by LangChain, ChromaDB, and GPT-3.5.
   >
   > No setup drama. No cloud fees. Just your data + local brainpower.
>>>>>>> 6603bbc (chore: clean repo, refactor Streamlit entrypoint, add CI, license, formatting)
